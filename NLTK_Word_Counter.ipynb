{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqzmScf2zU79kYg+JBP2Ah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazdakdev/AI-Bootcamp/blob/main/NLTK_Word_Counter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5lAMMkuufyt"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downlading required datasets"
      ],
      "metadata": {
        "id": "2exuUaP3_VL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "lRXE74Ixu_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\""
      ],
      "metadata": {
        "id": "Nlbn3SSixOio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "8Ro80jzIxmFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization\n",
        "### Examples of lemmatization:\n",
        "\n",
        "*   corpora : corpus\n",
        "*   better : good\n",
        "*   rocks : rock\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wEYOtnYT-1IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lemmatizer = WordNetLemmatizer()\n",
        "Lemmatized = [Lemmatizer.lemmatize(token) for token in tokens]"
      ],
      "metadata": {
        "id": "HxXUSY1N1rvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing stop words"
      ],
      "metadata": {
        "id": "xApOh6iz-E-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_tokens = [token for token in lem_ if token.lower() not in stop_words]"
      ],
      "metadata": {
        "id": "-4oZuCUt2rKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Words Counter\n",
        "### Calculate the usage of certian words in text "
      ],
      "metadata": {
        "id": "gBfoyLC6-oFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = Counter(filtered_tokens)\n",
        "word_count"
      ],
      "metadata": {
        "id": "vjQXBIYP2zrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kCp3Rps3p9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}